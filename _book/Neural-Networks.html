<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>10&nbsp; Deep Learning (Mostly Neural Networks) – Technical Interview Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Causal-Inference.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5e2915e4d4df5928b2b0a61215b328b6.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Neural-Networks.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep Learning (Mostly Neural Networks)</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Technical Interview Notes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data-viz.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Data Viz with Matplot</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./SQL.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">SQL</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Baby Stats</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Linear Regression and Shrinkage Estimators</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Bayesian-Stats.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bayesian Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tree-based-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Tree Based Methods and an Aside on Validation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./unsupervised-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Unsupervised Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Causal-Inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Causal Inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Neural-Networks.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep Learning (Mostly Neural Networks)</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#preface" id="toc-preface" class="nav-link active" data-scroll-target="#preface"><span class="header-section-number">10.1</span> Preface</a></li>
  <li><a href="#neural-networks" id="toc-neural-networks" class="nav-link" data-scroll-target="#neural-networks"><span class="header-section-number">10.2</span> Neural Networks</a></li>
  <li><a href="#what-is-a-derivative" id="toc-what-is-a-derivative" class="nav-link" data-scroll-target="#what-is-a-derivative"><span class="header-section-number">10.3</span> What is a derivative</a></li>
  <li><a href="#flavors-of-neural-networks" id="toc-flavors-of-neural-networks" class="nav-link" data-scroll-target="#flavors-of-neural-networks"><span class="header-section-number">10.4</span> Flavors of Neural Networks</a>
  <ul class="collapse">
  <li><a href="#image-processing-tasks" id="toc-image-processing-tasks" class="nav-link" data-scroll-target="#image-processing-tasks"><span class="header-section-number">10.4.1</span> Image Processing Tasks</a></li>
  <li><a href="#neural-networks-for-time-series-classification" id="toc-neural-networks-for-time-series-classification" class="nav-link" data-scroll-target="#neural-networks-for-time-series-classification"><span class="header-section-number">10.4.2</span> Neural Networks for Time Series Classification</a></li>
  </ul></li>
  <li><a href="#generative-models" id="toc-generative-models" class="nav-link" data-scroll-target="#generative-models"><span class="header-section-number">10.5</span> Generative Models</a>
  <ul class="collapse">
  <li><a href="#generative-adversarial-networks-gan" id="toc-generative-adversarial-networks-gan" class="nav-link" data-scroll-target="#generative-adversarial-networks-gan"><span class="header-section-number">10.5.1</span> Generative Adversarial Networks (GAN)</a></li>
  </ul></li>
  <li><a href="#so-how-do-these-work" id="toc-so-how-do-these-work" class="nav-link" data-scroll-target="#so-how-do-these-work"><span class="header-section-number">10.6</span> So How Do These Work?</a></li>
  <li><a href="#so-how-does-this-relate-to-generative-models" id="toc-so-how-does-this-relate-to-generative-models" class="nav-link" data-scroll-target="#so-how-does-this-relate-to-generative-models"><span class="header-section-number">10.7</span> So how does this relate to generative models?</a></li>
  <li><a href="#rag-architecture" id="toc-rag-architecture" class="nav-link" data-scroll-target="#rag-architecture"><span class="header-section-number">10.8</span> RAG architecture</a>
  <ul class="collapse">
  <li><a href="#how-does-it-work" id="toc-how-does-it-work" class="nav-link" data-scroll-target="#how-does-it-work"><span class="header-section-number">10.8.1</span> How does it work</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep Learning (Mostly Neural Networks)</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="preface" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="preface"><span class="header-section-number">10.1</span> Preface</h2>
<p>Right now this is going to cover lots of different things that feel a little scatter shot. This is because an interview I am prepping for is scant on detail but explicitly mentions a whole host of deep learning stuff.</p>
</section>
<section id="neural-networks" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="neural-networks"><span class="header-section-number">10.2</span> Neural Networks</h2>
<p>So I am just going to go through the zero to neural network video. One of the important basic concepts is back propagation.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> micrograd.engine <span class="im">import</span> Value </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> micrograd <span class="im">import</span> nn </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="op">-</span><span class="fl">4.0</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">+</span> b</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b <span class="op">+</span> b<span class="op">**</span><span class="dv">3</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>c <span class="op">+=</span> c <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>c <span class="op">+=</span> <span class="dv">1</span> <span class="op">+</span> c <span class="op">+</span> (<span class="op">-</span>a)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>d <span class="op">+=</span> d <span class="op">*</span> <span class="dv">2</span> <span class="op">+</span> (b <span class="op">+</span> a).relu()</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>d <span class="op">+=</span> <span class="dv">3</span> <span class="op">*</span> d <span class="op">+</span> (b <span class="op">-</span> a).relu()</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> c <span class="op">-</span> d</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e<span class="op">**</span><span class="dv">2</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> f <span class="op">/</span> <span class="fl">2.0</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>g <span class="op">+=</span> <span class="fl">10.0</span> <span class="op">/</span> f</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>g<span class="sc">.</span>data<span class="sc">:.4f}</span><span class="ss">'</span>) <span class="co"># prints 24.7041, the outcome of this forward pass</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>24.7041</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>g.backward()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>a<span class="sc">.</span>grad<span class="sc">:.4f}</span><span class="ss">'</span>) <span class="co"># prints 138.8338, i.e. the numerical value of dg/da</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>138.8338</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>b<span class="sc">.</span>grad<span class="sc">:.4f}</span><span class="ss">'</span>) <span class="co"># prints 645.5773, i.e. the numerical value of dg/db</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>645.5773</code></pre>
</div>
</div>
<p>Back propagation is going to start at g and recursively go back and apply the chain rule. We are going to be able to evaluate the derivative of g through each of the nodes c, d, e, f or the inputs of a and b. What this back propagation will tell us is what will end up happening to g if we nudge a or b. So the 138 of is the slope of the growth. Neural networks are simply just little math machines that take input data and the weights of a neural network as inputs into this math machine and output its predicitions.</p>
<p>None of the math changes we just end up bundling them to make it more efficient to actually train these things.</p>
</section>
<section id="what-is-a-derivative" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="what-is-a-derivative"><span class="header-section-number">10.3</span> What is a derivative</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">3</span><span class="op">*</span>x<span class="op">**</span><span class="dv">2</span><span class="op">-</span><span class="dv">4</span><span class="op">*</span>x<span class="op">+</span><span class="dv">5</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> np.arange(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="fl">0.25</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> f(xs)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>plt.plot(xs, ys)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Neural-Networks_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>So we are just going to define a scalar value function that takes a single scalar and returns a single scalar. What is the derivative of different points of x for this function. What a derivative is when we slightly increase an input say x how does the function respond with what sensitivity what is the slope how much does it go up or down.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="fl">3.0</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>f(x <span class="op">+</span> h)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>20.014003000000002</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>(f(x <span class="op">+</span> h) <span class="op">-</span> f(x))<span class="op">/</span>h</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>14.00300000000243</code></pre>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> <span class="op">-</span><span class="dv">3</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>(f(z <span class="op">+</span> h) <span class="op">-</span> f(z))<span class="op">/</span>h</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>-21.996999999998934</code></pre>
</div>
</div>
<p>as we start fiddling with it we get closer and closer to the true slope. When its at three its about 14. If we do this same excercise with a negative number. In a bit more of a complex case where we have three scalars as inputs and a single output. We are again going to look at the deriviatives for d for the inputs of a, b, and c</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">2.0</span> </span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="op">-</span><span class="dv">3</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> <span class="fl">10.0</span> </span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>d1 <span class="op">=</span> a <span class="op">*</span> b <span class="op">+</span> c </span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co"># inputs </span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>a <span class="op">+=</span> h </span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>d2 <span class="op">=</span> a <span class="op">*</span> b <span class="op">+</span> c</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"d1 = </span><span class="sc">{</span>d1<span class="sc">}</span><span class="ss">, d2 = </span><span class="sc">{</span>d2<span class="sc">}</span><span class="ss">, slope = </span><span class="sc">{</span>(d2<span class="op">-</span>d1)<span class="op">/</span>h<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>d1 = 4.0, d2 = 3.997, slope = -3.0000000000001137</code></pre>
</div>
</div>
<p>Here we are looking at the derivative of with respect to a so we are going to bump it by h. If we did it with b by a little bit</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">2.0</span> </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="op">-</span><span class="dv">3</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> <span class="fl">10.0</span> </span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>d1 <span class="op">=</span> a <span class="op">*</span> b <span class="op">+</span> c </span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># inputs </span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>b <span class="op">+=</span> h </span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>d2 <span class="op">=</span> a <span class="op">*</span> b <span class="op">+</span> c</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"d1 = </span><span class="sc">{</span>d1<span class="sc">}</span><span class="ss">, d2 = </span><span class="sc">{</span>d2<span class="sc">}</span><span class="ss">, slope = </span><span class="sc">{</span>(d2<span class="op">-</span>d1)<span class="op">/</span>h<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>d1 = 4.0, d2 = 4.002, slope = 1.9999999999997797</code></pre>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> graphviz <span class="im">import</span> Digraph</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> Value(<span class="fl">4.0</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">+</span> b <span class="op">*</span> z</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> c <span class="op">*</span> a</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> trace(root):</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    nodes, edges <span class="op">=</span> <span class="bu">set</span>(), <span class="bu">set</span>()</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> build(v):</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> v <span class="kw">not</span> <span class="kw">in</span> nodes:</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>            nodes.add(v)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> child <span class="kw">in</span> v._prev:</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>                edges.add((child, v))</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>                build(child)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    build(root)</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nodes, edges</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> trace(root):</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># builds a set of all nodes and edges in a graph</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>  nodes, edges <span class="op">=</span> <span class="bu">set</span>(), <span class="bu">set</span>()</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> build(v):</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> v <span class="kw">not</span> <span class="kw">in</span> nodes:</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>      nodes.add(v)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> child <span class="kw">in</span> v._prev:</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>        edges.add((child, v))</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>        build(child)</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>  build(root)</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> nodes, edges</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> draw_dot(root):</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>  dot <span class="op">=</span> Digraph(<span class="bu">format</span><span class="op">=</span><span class="st">'svg'</span>, graph_attr<span class="op">=</span>{<span class="st">'rankdir'</span>: <span class="st">'LR'</span>}) <span class="co"># LR = left to right</span></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>  nodes, edges <span class="op">=</span> trace(root)</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> n <span class="kw">in</span> nodes:</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>    uid <span class="op">=</span> <span class="bu">str</span>(<span class="bu">id</span>(n))</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># for any value in the graph, create a rectangular ('record') node for it</span></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>    dot.node(name <span class="op">=</span> uid, label <span class="op">=</span> <span class="st">"{ </span><span class="sc">%s</span><span class="st"> | data </span><span class="sc">%.4f</span><span class="st"> | grad </span><span class="sc">%.4f</span><span class="st"> }"</span> <span class="op">%</span> (n.label, n.data, n.grad), shape<span class="op">=</span><span class="st">'record'</span>)</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> n._op:</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>      <span class="co"># if this value is a result of some operation, create an op node for it</span></span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>      dot.node(name <span class="op">=</span> uid <span class="op">+</span> n._op, label <span class="op">=</span> n._op)</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>      <span class="co"># and connect this node to it</span></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>      dot.edge(uid <span class="op">+</span> n._op, uid)</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> n1, n2 <span class="kw">in</span> edges:</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># connect n1 to the op node of n2</span></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>    dot.edge(<span class="bu">str</span>(<span class="bu">id</span>(n1)), <span class="bu">str</span>(<span class="bu">id</span>(n2)) <span class="op">+</span> n2._op)</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> dot</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> Value(<span class="fl">1.0</span>)</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (x <span class="op">*</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">1</span>).relu()</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>dot <span class="op">=</span> draw_dot(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Where this gets a little bitter harder mentally as a political scientist is that there are a lot of these layers. The input of the next layer is effectively a weighted transformation of the previous layer with a nonlinear function applied to it. So it is not neccessarily ‘independent’ in the strictest sense of the term. W</p>
<p>The thing about neural networks it will keep track all of all these little steps. Then using backpropagation to see how all these little weights impact the loss function. Backpropagation lets us keep track of what weights actually led us down the wrong path.</p>
<p>We use backpropagation to compute partial derivatives of the loss with respect to the weights using the chain rule. Neurons apply activation functions to introduce non-linearity. We don’t control the input data, but we can tune the weights, which are initially random. If doing classification, we often apply softmax in the final layer to produce predicted probabilities. These predictions are compared to true labels via a loss function, which guides weight updates using gradient descent (which uses first-order derivatives, not second-order). The learning rate controls the step size, and we iterate this process over multiple epochs to optimize the model.</p>
</section>
<section id="flavors-of-neural-networks" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="flavors-of-neural-networks"><span class="header-section-number">10.4</span> Flavors of Neural Networks</h2>
<p>One really intersting usage of Neural Networks is the NFL. We have a lot of game film that we need to sort through and do it efficiently. We need to track tendencies which entails us correctly being able to determine coverages and where players are positionally on the field. However, this is a really complex task when we break it out into what we are asking the model to do. For an army of football nerds this is not that difficult it is just time consuming.</p>
<p>We have lots of things that are going on we have sequential data in the time, but we also have sequential data in the down and distance which are dependent on one another. We are less likely to see a team pass on 3rd and 1 then we are if they are 3rd and 10. How we got to those down and distances are also dependent on what happened the down before. Play calling is also dictated by the game clock and score. If we are down 6 in the 4th quarter with two minutes left to go with no timeouts running is going to be less likely. How players shift and where they are on the field is also dependent on playclock. Where a player is on offense is going to be dictated by the playclock. If we send a receiver in motion they have to be where they are supposed to be by the time that ball is snapped, and same with defensive players. Using neural networks we can at least make this process more efficient and through careful retraining we can get the model pretty good at identifying and predicting various things.</p>
<p>Within this example there are two intermingled tasks that require different neural network architectures. We have a time series classification task to predict what coverages or plays the offense is running. We also have a prediction task where we are trying to predict who is most likely to be the blitzer or who is going to get the ball. These are then intermingled with a computer vision task. While related they require changes in the underlying linear algebra.</p>
<section id="image-processing-tasks" class="level3" data-number="10.4.1">
<h3 data-number="10.4.1" class="anchored" data-anchor-id="image-processing-tasks"><span class="header-section-number">10.4.1</span> Image Processing Tasks</h3>
<p>Neural networks are pretty adept and vision processing tasks. Part of the reason this they are really good at this is because we can use convulations to classify and identify images. Convolutions are really just a filter matrix where we take a matrix of some width and length from the image and then mutliplies it by another matrix which we call a filter. This filter is a smaller part of the image. We then multiply these two matrices to get a score. A high score indicates that the input images is similar to the filter. The filters will be learned via training. So if we take an NFL field we have two directions that the model can learn. North-South where the end zone the offense is trying to get to is North. We also have East-West where the sidelines to the quarterback’s throwing arm could be east if they are a right handed quarterback. We would take these two directions and generate “two” images for the filters. We then multiply the input image matrix by these two different filter matrices. As the model gets more complex we get more of these filters and multiply the input image by more of these filters. So in the next layer we would capture the width of the widest players on the East-West axis and the distance from the receiver and the cornerback on the North-South Axis. We can then differentiate the teams by differences in there jersey colors and the details of the decals as we get further down the layers of the network. Each time we convolve we apply multiply a region by this filter and then sum all those dot product to get a scalar. So we would do something to this effect.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>input_matrix <span class="op">=</span> np.array([[<span class="dv">8</span>, <span class="dv">4</span>, <span class="dv">4</span>,<span class="dv">2</span> ,<span class="dv">8</span>],</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">5</span>,<span class="dv">4</span>, <span class="dv">6</span>],</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>,<span class="dv">7</span>, <span class="dv">2</span>]])</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>filter_matrix <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">0</span>], </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>                          [<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>]])</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>flipped_filter <span class="op">=</span> np.flipud(np.fliplr(filter_matrix))</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>region_one <span class="op">=</span> np.array([[<span class="dv">8</span>,<span class="dv">4</span>],</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>                       [<span class="dv">6</span>,<span class="dv">7</span>],</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>                       [<span class="dv">2</span>,<span class="dv">1</span>]])</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>convolution_result <span class="op">=</span> np.<span class="bu">sum</span>(np.dot(region_one, flipped_filter))</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>convolution_result <span class="op">=</span> np.<span class="bu">sum</span>(convolution_result)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Convolution result:"</span>, convolution_result)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Convolution result: 28</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Whats happening:"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Whats happening:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>flipped_filter[<span class="dv">0</span>,<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> * </span><span class="sc">{</span>region_one[<span class="dv">0</span>,<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> + </span><span class="sc">{</span>flipped_filter[<span class="dv">0</span>,<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> * </span><span class="sc">{</span>region_one[<span class="dv">0</span>,<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> + "</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f"</span><span class="sc">{</span>flipped_filter[<span class="dv">1</span>,<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> * </span><span class="sc">{</span>region_one[<span class="dv">1</span>,<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> + </span><span class="sc">{</span>flipped_filter[<span class="dv">1</span>,<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> * </span><span class="sc">{</span>region_one[<span class="dv">1</span>,<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> = </span><span class="sc">{</span>convolution_result<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2 * 8 + -1 * 4 + 0 * 6 + 1 * 7 = 28</code></pre>
</div>
</div>
<p>After these convolutions we then pool the convolutions by taking, typically, non-overlapping 2x2 blocks and place them in a matrix with the maximum of those two by two blocks. So if we go ahead and convolve the entire input matrix we get something like this</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.signal <span class="im">import</span> convolve2d</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>convolution_result <span class="op">=</span> convolve2d(input_matrix, filter_matrix, mode <span class="op">=</span> <span class="st">'valid'</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>convolution_result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>array([[19,  9, 10,  2],
       [ 6, 12, 13,  4]])</code></pre>
</div>
</div>
<p>Then in the pooling result we would get a pooled matrix that would effectively be a matrix with the values of 19 and 13. Except this would be a much much bigger matrix. We then take this slightly smaller matrix and then pass it through another convolution layer with smaller number of filters and so on and so forth until we get a single image. We can do a similar thing with lower quality images where we deconvolve them. This is less that we are reversing the convolution process but we are convolving the inputs like usual but we change the filter a bit.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>flip_one <span class="op">=</span> np.flipud(filter_matrix)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>flip_two <span class="op">=</span> np.fliplr(flip_one)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original Filter Matrix:</span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>filter_matrix<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f"After Flipping North-South:</span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>flip_one<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f"After Flipping East-West: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>flip_two<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original Filter Matrix:
 [[ 1  0]
 [-1  2]]
After Flipping North-South:
 [[-1  2]
 [ 1  0]]
 After Flipping East-West: 
 [[ 2 -1]
 [ 0  1]]</code></pre>
</div>
</div>
<p>What we are effectively doing is expanding the search over many grainy pixels rather than focusing on narrower regions of a high quality images. If we have many big pixels this has the advantage of expanding the underlying matrix and in the best case scenarios filling them with the correct values that then get turned back into colors, textures, etc to make a higher quality image.</p>
</section>
<section id="neural-networks-for-time-series-classification" class="level3" data-number="10.4.2">
<h3 data-number="10.4.2" class="anchored" data-anchor-id="neural-networks-for-time-series-classification"><span class="header-section-number">10.4.2</span> Neural Networks for Time Series Classification</h3>
<p>One nice feature that people have found is that Neural Networks are actually pretty good at modeling time series for multiclass prediction problems. If we cheat a little bit and add units to this problem in a two class problem this just becomes a survival model. What is nice is that we can model duration dependence by creating duration dummies and then including duration, <span class="math inline">\(duration^2\)</span>, and <span class="math inline">\(duration^3\)</span> as variables in our models or splines <span class="citation" data-cites="carterBackFutureModeling2010">(<a href="#ref-carterBackFutureModeling2010" role="doc-biblioref">Carter and Signorino 2010</a>)</span>. This becomes a bit more difficult when we are in a multiclass prediction world, but this would effectively just be a competing risks model.</p>
<p>In effect what goes on in a recurrent neural network is that weights are reused between layers by keeping them stored in the hidden layers. In a cannonical NN each layer will generate its own weights independent of the prior layer. We then just use back propagation to track everything and update the weights once we pass everything to through the softmax function. However, in an RNN we store everything we learn in a vector containing information we learned in a prior layer which are then used to learn the weights for the next layer. Then we repeat this process for the next layer.</p>
<p>To make this a bit clearer. We start with training our model with the first point in our time series where some combination of inputs values, hyperparameters, and some randomly initialized weights plus an activation function. We then capture the outputs of that layer and store it as a vector. We then effectively use these outputs as a lagged dependent variable to help us predict the next output. This repeats for each time then we use back propagation through time to understand which hidden state is responsible for bad forecasts or classification.</p>
</section>
</section>
<section id="generative-models" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="generative-models"><span class="header-section-number">10.5</span> Generative Models</h2>
<section id="generative-adversarial-networks-gan" class="level3" data-number="10.5.1">
<h3 data-number="10.5.1" class="anchored" data-anchor-id="generative-adversarial-networks-gan"><span class="header-section-number">10.5.1</span> Generative Adversarial Networks (GAN)</h3>
<p>These were interesting and new to me. These are used in a lot of image, video, and audio tasks mostly of the generative variety. So if you think of deep fakes these are done via a GAN in a lot of cases. It is kind of funny because the opening example of one of the most cited reviews is that of a forger and an art expert. So imagine we have a new art expert who is learning the tricks of the trade pitted against a new art forger. The art forger will generate images without access to the reference material and the art expert will authenticate them against real images. This is happening in an iterative process the art forger given an infinite number of iterations will eventually become a good enough forger to slip some images past the art forger.</p>
<p>While they are in competition with each other they are intimately linked. The loss function that both the forger and the expert are trying to minimize are intimately linked. The tasks that are GANs are often tasked with are incredibly difficult. Grounding it in our art example mixing colors correctly and making putting them on the canvas correctly is difficult. Lets take a very simple example where the forger is trying to get the correct color. In 1000 tries to get the colors correctly the forger is going to get some correct but it is going to get a lot wrong</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>art_forger_examp <span class="ot">=</span> <span class="fu">tibble</span>(<span class="st">`</span><span class="at">Fake Color</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">8</span>),</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>                              <span class="st">`</span><span class="at">Real Color</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">2</span>)) <span class="sc">|&gt;</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>                            <span class="fu">pivot_longer</span>(<span class="fu">everything</span>())</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(art_forger_examp, <span class="fu">aes</span>(<span class="at">x =</span> value, <span class="at">fill =</span> name)) <span class="sc">+</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">fill =</span> <span class="cn">NULL</span>, <span class="at">x =</span> <span class="cn">NULL</span>) <span class="sc">+</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Neural-Networks_files/figure-html/unnamed-chunk-10-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>As the number of adversarial interactions increase the forger is going to get better at getting the color correct.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>iterative_interactions <span class="ot">&lt;-</span> <span class="cf">function</span>(n, <span class="at">m =</span> <span class="dv">2</span>, <span class="at">m2_start =</span> <span class="dv">8</span>, <span class="at">steps =</span> <span class="dv">5</span>) {</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  mean_fake_values <span class="ot">&lt;-</span> <span class="fu">seq</span>(m2_start, m, <span class="at">length.out =</span> steps)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  plots <span class="ot">&lt;-</span> <span class="fu">map</span>(mean_fake_values, <span class="cf">function</span>(m2) {</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    plot_dat <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>      <span class="st">`</span><span class="at">Fake Color</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> m2),</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>      <span class="st">`</span><span class="at">Real Color</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> m)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span> tidyr<span class="sc">::</span><span class="fu">pivot_longer</span>(<span class="fu">everything</span>())</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(plot_dat, <span class="fu">aes</span>(<span class="at">x =</span> value, <span class="at">fill =</span> name)) <span class="sc">+</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>      <span class="fu">labs</span>(<span class="at">fill =</span> <span class="cn">NULL</span>, <span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">title =</span> <span class="fu">paste</span>(<span class="st">"Mean Fake:"</span>, <span class="fu">round</span>(m2, <span class="dv">2</span>))) <span class="sc">+</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_minimal</span>()</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Combine the plots using patchwork</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">wrap_plots</span>(plots, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Run simulation for different sample sizes</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>sims <span class="ot">&lt;-</span> <span class="fu">iterative_interactions</span>(<span class="at">n =</span> <span class="dv">10000</span>, <span class="at">steps =</span> <span class="dv">4</span>)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>sims</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Neural-Networks_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Effectively as the art forger banks more and more information they will start get better at this. This step repeats for every part of the image.</p>
</section>
</section>
<section id="so-how-do-these-work" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="so-how-do-these-work"><span class="header-section-number">10.6</span> So How Do These Work?</h2>
<p>For LLM’s and these generative models we have to look at Attention, Encoders, and decoders the entire architecture is known as a transformer. The foundational paper in these models gets the idea from translations. In gendered languages like French or Spanish is going to point the translator in the wrong direction. Take le homme mange or the man eats in French. Homme doesn’t depend on any other word in the sentence but the and eats depends on man. Le could be la, nous, or ils depending the number of men and mange could mangeons or mangent depending on tense. For a sentence in any language a word is going to attend to another word in the sentence but not all of them.</p>
<p>In the model attention works kind of like a key value pair where attention is the dot product of the query and the key. Or in another words</p>
<p><span class="math display">\[
\text{Attention Weights} = \text{What the work is looking for in another words} \times \text{The actual representation of the word that gets passed along}
\]</span></p>
<p>Where we get a score of how much one word should pay attention to another. We then feed it into a sofmax function to effectively spit out weights that can be interpreted as probabilities. So an attention score of 0.000001 means that a word has a low probability of attending to another. So in our French example homme would have a low probability of attending to any other word in the example. For computational purposes we stack these into multiple layers to create a multiheaded attention check. So instead of doing the attention of one word to another sequentially we can compute the relation of each word to each other much quicker.</p>
<p>An encoder in these models is really just comprised of N layers of these attention scores and a neural network. The NN is critical to actually compute word embeddings and to calculate where the word is in N dimensions and capture the relationship between words positionally and with respect to the whole context window and relationships in the entire sentence. So in an example sentence of I am really really hungry and haven’t had fried chicken in awhile lets go eat at KFC. The first layer could have a multiheaded attention check and a NN that looks at the relationship between words directly next to each other where we would focus on the sematantic relationship between “had”, “fried”, and “chicken” then the last layer would look at the temporal relationship between awhile and fried chicken. The stack is also important because we are taking the residuals of one layer and using it in the next layer. So the model would “understand” that ‘fried’ and ‘chicken’ have high attention scores. Then this result would be passed onto the next layer so it doesn’t have to relearn the semantic relationship and focus on other semantic relationship. In effect we are looking at a form of boosting where the results of one ‘tree’ impacts the way the next ‘tree’ is going to learn.</p>
<p>You can think of the encoder as producing a kind of “cumulative” attention score for each word, reflecting how each word relates to the others. The decoder then takes those cumulative attention scores and applies a second layer of attention—focusing on different parts of the encoder’s output to generate the next part of the output sequence. This makes the decoder’s understanding of the input sequence more nuanced and dynamic.</p>
<p>An additional revolution in this literature comes from <span class="citation" data-cites="DBLP:journals/corr/abs-1810-04805">Devlin et al. (<a href="#ref-DBLP:journals/corr/abs-1810-04805" role="doc-biblioref">2018</a>)</span> where they add a subtle but powerful augmentation of this transformer architecture. For the most part, the majority of languages read right to left. Instead of simple left-right attention BERT uses bidirectional self-attention letting the model consider prior and preceding words. Self-attention is simply the idea that we focus the attention locally where the word’s meaning is determined within the sentence. Attention would pick up on a larger global definition . So if we think about sports we could have two sentences with dog in them. For example lets take this passage &gt; “Matthew Stafford was a Georgia Bulldog. Matthew Stafford is known for his toughness he once led a comeback of a game where he separated his shoulder, he is a dog. The Staffords have a dog named Jack”</p>
<p>If we tasked a model with a Next Sentence Prediction (NSP) task using a standard transformer, it might predict the second sentence based on the global frequency of the word “dog” as the animal, especially if it has not seen enough context to disambiguate the term. This could result in the model misunderstanding that “dog” refers to toughness in the second instance.</p>
<p>For example, if we asked the model, “What are some examples of NFL players being dogs?”, the model might produce responses based only on the animal interpretation, because the word “dog” in the input text was not disambiguated properly. However, with self-attention, the model can better capture the contextual differences, focusing on the surrounding words like “toughness” and “comeback” to understand that “dog” here refers to toughness, rather than the literal animal</p>
<p>The combination of self-attention and bidirectionality is an inherently powerful idea. However, by combining these layers of complexity this can lead to overfitting. In the context of a NLP task all this means is that we will start to get semantic relationships that don’t make a ton of sense. To guard against this we could, theoretically, impose some regularization on the underlying neural networks. This would likely significantly impact the training time making an already expensive process more expensive. A cheaper alternative is to simply hide some words randomly and then after the encoder layer have the model predict the masked word. This ensures that the model isn’t just using one direction to improve its predictions and we are getting semantically meaningful relationships.</p>
<p>OpenAI is a major player in the space of large language models (LLMs). Text data is inherently multi-dimensional, and fine-tuning a model for a specific task is both expensive and requires a large corpus of task-specific data, which might not be feasible for smaller datasets. Instead of starting with a task-specific model, OpenAI and other organizations working with LLMs often use a task-agnostic approach.</p>
<p>The process starts with feeding the model a diverse corpus of data rather than just task-specific documents. This is effective because GPTs (Generative Pre-trained Transformers) leverage the pretrained knowledge from a wide array of texts. Unlike some earlier models, GPTs do not rely solely on RNNs (Recurrent Neural Networks), but rather on the transformer architecture, which doesn’t store information between layers in the same way RNNs do. Instead, transformers use self-attention mechanisms that enable the model to better capture contextual relationships between words across the entire input sequence.</p>
<p>Despite not being specifically trained for a task initially, the model can still apply its preexisting, general knowledge learned during pretraining to new, task-specific corpora. This approach allows for more efficient fine-tuning with smaller datasets, as the model is able to build on the knowledge it has already acquired. This approach is related to the Retrieval-Augmented Generation (RAG) framework, where the model can retrieve relevant information from a large corpus and generate task-specific outputs.</p>
<p>GPT models also have a variety of hyperparameters that influence their behavior. One of the most well-known is temperature, which controls the probability distribution from which words are sampled. Higher temperatures (e.g., 1.0 or above) allow the model to pick words from the tail of the distribution, leading to more diverse but less predictable output. Conversely, a lower temperature (e.g., 0.2 or 0.5) narrows the distribution, making the model more deterministic and focused on high-probability words.</p>
<p>While the temperature is just one of many hyperparameters, there are potentially billions of parameters in the model, each contributing to various aspects of the language and its understanding. These parameters allow the model to grasp complex semantic relationships and context, enhancing its ability to perform diverse tasks.</p>
<p>A crucial element of OpenAI’s approach is the use of semi-supervised learning, which integrates reinforcement learning into the training process. One way this is applied is through few-shot learning, where the model is provided with a few labeled examples of the task it is being trained to perform. These labeled examples serve as a form of ground truth, which helps guide the model’s predictions.</p>
<p>In addition to few-shot learning, fine-tuning is a key process in improving the model’s output for specific tasks. For example, if the model is tasked with generating Python code but the output is inefficient, an expert can provide a more efficient code example to refine the model’s performance. This feedback loop allows the model to continuously improve based on real-world feedback and domain expertise.</p>
</section>
<section id="so-how-does-this-relate-to-generative-models" class="level2" data-number="10.7">
<h2 data-number="10.7" class="anchored" data-anchor-id="so-how-does-this-relate-to-generative-models"><span class="header-section-number">10.7</span> So how does this relate to generative models?</h2>
<p>Effectively we are doing the same thing with images. If we are generating art we are making attention scores with the position of the colors and the location in an image and the orientation of the pixels. Our forger is effectively just as series of encoders and decoders that makes art and our expert is effectively just a series of encoders and decoders that score the image as fake or real by taking the generated image and a real image and comparing the attention scores</p>
</section>
<section id="rag-architecture" class="level2" data-number="10.8">
<h2 data-number="10.8" class="anchored" data-anchor-id="rag-architecture"><span class="header-section-number">10.8</span> RAG architecture</h2>
<p>One of the major things companies are interested in these days is Retrieval Augmented Generation with vector search (RAG). The general idea of RAG is that lets say we have a question about pandas. LLM’s are likely going to have a large pool of examples where they can pull relevant code from. However, lets say pandas updates its API at time + 1 from when the model was last trained and deprecates well known functions in favor of doing something. We are running the model locally and don’t have access to the internet but we have downloaded a copy of the pandas documentation. The model is going to do its best to output the right answer but is never really going to acknowledge that it doesn’t know something so it will ‘hallucinate’ answers. We can use this new document to augment things and get the appropriate answers we want.</p>
<p>This is kind of the entire idea of the RAG framework. As a company its not neccessarily cost effective or legal to have Anthropic or OpenAi train a bespoke model or turn over confidential records to train a model on. This data is going to pop up in ways we can’t anticipate. Instead we can use RAG to augment our model.</p>
<section id="how-does-it-work" class="level3" data-number="10.8.1">
<h3 data-number="10.8.1" class="anchored" data-anchor-id="how-does-it-work"><span class="header-section-number">10.8.1</span> How does it work</h3>
<p><span class="math display">\[
\text{user} \overbrace{\rightarrow}^{\text{prompt}} \text{Vector Data Base of Word emeddings} \overbrace{\rightarrow}^{\text{Relevant Sources}} \text{User prompt meets relevant source} \rightarrow Model \rightarrow Output
\]</span></p>
<p>The general idea is that we take our relevant documents and convert them into embeddings and take the user’s prompt and convert them to embeddings. We are kind of effectively taking our prompt and a document with a very close semantic relationship and then generate relevant output based on the most comparable document.</p>
<p>What does this look like? Lets take Positron the new IDE by Posit. It is still a pretty young so it is not in the training dataset</p>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Without RAG
</div>
</div>
<div class="callout-body-container callout-body">
<p>User: What is Positron?</p>
<p>Output: The Positron IDE is a lightweight, fast, and customizable code editor designed to provide a simple and intuitive environment for software development. It was originally built as a plugin for Atom, a popular open-source text editor. Positron aimed to combine the best aspects of an editor (like Atom) with a focus on speed and simplicity.</p>
</div>
</div>
<p>None of this is actually correct in the context of what I was looking for. ChatGpt gave kind of a general definition of an IDE. Lets say that the internal documents were available for Zed and Positron and we wanted to ensure that an LLM would output useful information for our IDE. We could take these documents and then make embeddings then add it to a vector database. Now our query would look something like this</p>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
With RAG
</div>
</div>
<div class="callout-body-container callout-body">
<p>User: What is Positron Model: A next-generation data science IDE built by Posit PBC An extensible, polyglot tool for writing code and exploring data A familiar environment for reproducible authoring and publishing</p>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-carterBackFutureModeling2010" class="csl-entry" role="listitem">
Carter, David B, and Curtis S Signorino. 2010. <span>“Back to the <span>Future</span>: <span>Modeling Time Dependence</span> in <span>Binary Data</span>.”</span> <em>Political Analysis</em> 18 (3): 271–92. <a href="https://doi.org/10.1093/pan/mpq013">https://doi.org/10.1093/pan/mpq013</a>.
</div>
<div id="ref-DBLP:journals/corr/abs-1810-04805" class="csl-entry" role="listitem">
Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. <span>“<span>BERT</span>: <span class="nocase">Pre-training</span> of Deep Bidirectional Transformers for Language Understanding.”</span> <em>CoRR</em> abs/1810.04805. <a href="http://arxiv.org/abs/1810.04805">http://arxiv.org/abs/1810.04805</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Causal-Inference.html" class="pagination-link" aria-label="Causal Inference">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Causal Inference</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->




</body></html>